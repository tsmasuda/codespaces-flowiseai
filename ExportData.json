{
  "Tool": [],
  "ChatFlow": [
    {
      "id": "44d42b4c-5839-4d79-8535-9679dbc7ad25",
      "name": "Basic Chat",
      "flowData": "{\n  \"nodes\": [\n    {\n      \"id\": \"chatOpenAI_0\",\n      \"position\": {\n        \"x\": 118.38002127520144,\n        \"y\": 39.211301254600286\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"chatOpenAI_0\",\n        \"label\": \"ChatOpenAI\",\n        \"version\": 8,\n        \"name\": \"chatOpenAI\",\n        \"type\": \"ChatOpenAI\",\n        \"baseClasses\": [\n          \"ChatOpenAI\",\n          \"BaseChatModel\",\n          \"BaseLanguageModel\",\n          \"Runnable\"\n        ],\n        \"category\": \"Chat Models\",\n        \"description\": \"Wrapper around OpenAI large language models that use the Chat endpoint\",\n        \"inputParams\": [\n          {\n            \"label\": \"Connect Credential\",\n            \"name\": \"credential\",\n            \"type\": \"credential\",\n            \"credentialNames\": [\n              \"openAIApi\"\n            ],\n            \"id\": \"chatOpenAI_0-input-credential-credential\"\n          },\n          {\n            \"label\": \"Model Name\",\n            \"name\": \"modelName\",\n            \"type\": \"asyncOptions\",\n            \"loadMethod\": \"listModels\",\n            \"default\": \"gpt-4o-mini\",\n            \"id\": \"chatOpenAI_0-input-modelName-asyncOptions\"\n          },\n          {\n            \"label\": \"Temperature\",\n            \"name\": \"temperature\",\n            \"type\": \"number\",\n            \"step\": 0.1,\n            \"default\": 0.9,\n            \"optional\": true,\n            \"id\": \"chatOpenAI_0-input-temperature-number\"\n          },\n          {\n            \"label\": \"Streaming\",\n            \"name\": \"streaming\",\n            \"type\": \"boolean\",\n            \"default\": true,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-streaming-boolean\"\n          },\n          {\n            \"label\": \"Max Tokens\",\n            \"name\": \"maxTokens\",\n            \"type\": \"number\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-maxTokens-number\"\n          },\n          {\n            \"label\": \"Top Probability\",\n            \"name\": \"topP\",\n            \"type\": \"number\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-topP-number\"\n          },\n          {\n            \"label\": \"Frequency Penalty\",\n            \"name\": \"frequencyPenalty\",\n            \"type\": \"number\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-frequencyPenalty-number\"\n          },\n          {\n            \"label\": \"Presence Penalty\",\n            \"name\": \"presencePenalty\",\n            \"type\": \"number\",\n            \"step\": 0.1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-presencePenalty-number\"\n          },\n          {\n            \"label\": \"Timeout\",\n            \"name\": \"timeout\",\n            \"type\": \"number\",\n            \"step\": 1,\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-timeout-number\"\n          },\n          {\n            \"label\": \"BasePath\",\n            \"name\": \"basepath\",\n            \"type\": \"string\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-basepath-string\"\n          },\n          {\n            \"label\": \"Proxy Url\",\n            \"name\": \"proxyUrl\",\n            \"type\": \"string\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-proxyUrl-string\"\n          },\n          {\n            \"label\": \"Stop Sequence\",\n            \"name\": \"stopSequence\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"optional\": true,\n            \"description\": \"List of stop words to use when generating. Use comma to separate multiple stop words.\",\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-stopSequence-string\"\n          },\n          {\n            \"label\": \"BaseOptions\",\n            \"name\": \"baseOptions\",\n            \"type\": \"json\",\n            \"optional\": true,\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-baseOptions-json\"\n          },\n          {\n            \"label\": \"Allow Image Uploads\",\n            \"name\": \"allowImageUploads\",\n            \"type\": \"boolean\",\n            \"description\": \"Allow image input. Refer to the <a href=\\\"https://docs.flowiseai.com/using-flowise/uploads#image\\\" target=\\\"_blank\\\">docs</a> for more details.\",\n            \"default\": false,\n            \"optional\": true,\n            \"id\": \"chatOpenAI_0-input-allowImageUploads-boolean\"\n          },\n          {\n            \"label\": \"Image Resolution\",\n            \"description\": \"This parameter controls the resolution in which the model views the image.\",\n            \"name\": \"imageResolution\",\n            \"type\": \"options\",\n            \"options\": [\n              {\n                \"label\": \"Low\",\n                \"name\": \"low\"\n              },\n              {\n                \"label\": \"High\",\n                \"name\": \"high\"\n              },\n              {\n                \"label\": \"Auto\",\n                \"name\": \"auto\"\n              }\n            ],\n            \"default\": \"low\",\n            \"optional\": false,\n            \"additionalParams\": true,\n            \"id\": \"chatOpenAI_0-input-imageResolution-options\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Cache\",\n            \"name\": \"cache\",\n            \"type\": \"BaseCache\",\n            \"optional\": true,\n            \"id\": \"chatOpenAI_0-input-cache-BaseCache\"\n          }\n        ],\n        \"inputs\": {\n          \"cache\": \"\",\n          \"modelName\": \"gpt-4o-mini\",\n          \"temperature\": 0.9,\n          \"streaming\": true,\n          \"maxTokens\": \"\",\n          \"topP\": \"\",\n          \"frequencyPenalty\": \"\",\n          \"presencePenalty\": \"\",\n          \"timeout\": \"\",\n          \"basepath\": \"\",\n          \"proxyUrl\": \"\",\n          \"stopSequence\": \"\",\n          \"baseOptions\": \"\",\n          \"allowImageUploads\": true,\n          \"imageResolution\": \"low\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable\",\n            \"name\": \"chatOpenAI\",\n            \"label\": \"ChatOpenAI\",\n            \"description\": \"Wrapper around OpenAI large language models that use the Chat endpoint\",\n            \"type\": \"ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 670,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 118.38002127520144,\n        \"y\": 39.211301254600286\n      },\n      \"dragging\": false\n    },\n    {\n      \"id\": \"conversationChain_0\",\n      \"position\": {\n        \"x\": 684.6188912143675,\n        \"y\": 189.94249339333606\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"conversationChain_0\",\n        \"label\": \"Conversation Chain\",\n        \"version\": 3,\n        \"name\": \"conversationChain\",\n        \"type\": \"ConversationChain\",\n        \"baseClasses\": [\n          \"ConversationChain\",\n          \"LLMChain\",\n          \"BaseChain\",\n          \"Runnable\"\n        ],\n        \"category\": \"Chains\",\n        \"description\": \"Chat models specific conversational chain with memory\",\n        \"inputParams\": [\n          {\n            \"label\": \"System Message\",\n            \"name\": \"systemMessagePrompt\",\n            \"type\": \"string\",\n            \"rows\": 4,\n            \"description\": \"If Chat Prompt Template is provided, this will be ignored\",\n            \"additionalParams\": true,\n            \"optional\": true,\n            \"default\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\",\n            \"placeholder\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\",\n            \"id\": \"conversationChain_0-input-systemMessagePrompt-string\"\n          }\n        ],\n        \"inputAnchors\": [\n          {\n            \"label\": \"Chat Model\",\n            \"name\": \"model\",\n            \"type\": \"BaseChatModel\",\n            \"id\": \"conversationChain_0-input-model-BaseChatModel\"\n          },\n          {\n            \"label\": \"Memory\",\n            \"name\": \"memory\",\n            \"type\": \"BaseMemory\",\n            \"id\": \"conversationChain_0-input-memory-BaseMemory\"\n          },\n          {\n            \"label\": \"Chat Prompt Template\",\n            \"name\": \"chatPromptTemplate\",\n            \"type\": \"ChatPromptTemplate\",\n            \"description\": \"Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable\",\n            \"optional\": true,\n            \"id\": \"conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate\"\n          },\n          {\n            \"label\": \"Input Moderation\",\n            \"description\": \"Detect text that could generate harmful output and prevent it from being sent to the language model\",\n            \"name\": \"inputModeration\",\n            \"type\": \"Moderation\",\n            \"optional\": true,\n            \"list\": true,\n            \"id\": \"conversationChain_0-input-inputModeration-Moderation\"\n          }\n        ],\n        \"inputs\": {\n          \"model\": \"{{chatOpenAI_0.data.instance}}\",\n          \"memory\": \"{{bufferMemory_0.data.instance}}\",\n          \"chatPromptTemplate\": \"\",\n          \"inputModeration\": \"\",\n          \"systemMessagePrompt\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"conversationChain_0-output-conversationChain-ConversationChain|LLMChain|BaseChain|Runnable\",\n            \"name\": \"conversationChain\",\n            \"label\": \"ConversationChain\",\n            \"description\": \"Chat models specific conversational chain with memory\",\n            \"type\": \"ConversationChain | LLMChain | BaseChain | Runnable\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 435,\n      \"positionAbsolute\": {\n        \"x\": 684.6188912143675,\n        \"y\": 189.94249339333606\n      },\n      \"selected\": false\n    },\n    {\n      \"id\": \"bufferMemory_0\",\n      \"position\": {\n        \"x\": 121.69949453914967,\n        \"y\": 742.2950675794249\n      },\n      \"type\": \"customNode\",\n      \"data\": {\n        \"id\": \"bufferMemory_0\",\n        \"label\": \"Buffer Memory\",\n        \"version\": 2,\n        \"name\": \"bufferMemory\",\n        \"type\": \"BufferMemory\",\n        \"baseClasses\": [\n          \"BufferMemory\",\n          \"BaseChatMemory\",\n          \"BaseMemory\"\n        ],\n        \"category\": \"Memory\",\n        \"description\": \"Retrieve chat messages stored in database\",\n        \"inputParams\": [\n          {\n            \"label\": \"Session Id\",\n            \"name\": \"sessionId\",\n            \"type\": \"string\",\n            \"description\": \"If not specified, a random id will be used. Learn <a target=\\\"_blank\\\" href=\\\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\\\">more</a>\",\n            \"default\": \"\",\n            \"additionalParams\": true,\n            \"optional\": true,\n            \"id\": \"bufferMemory_0-input-sessionId-string\"\n          },\n          {\n            \"label\": \"Memory Key\",\n            \"name\": \"memoryKey\",\n            \"type\": \"string\",\n            \"default\": \"chat_history\",\n            \"additionalParams\": true,\n            \"id\": \"bufferMemory_0-input-memoryKey-string\"\n          }\n        ],\n        \"inputAnchors\": [],\n        \"inputs\": {\n          \"sessionId\": \"\",\n          \"memoryKey\": \"chat_history\"\n        },\n        \"outputAnchors\": [\n          {\n            \"id\": \"bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory\",\n            \"name\": \"bufferMemory\",\n            \"label\": \"BufferMemory\",\n            \"description\": \"Retrieve chat messages stored in database\",\n            \"type\": \"BufferMemory | BaseChatMemory | BaseMemory\"\n          }\n        ],\n        \"outputs\": {},\n        \"selected\": false\n      },\n      \"width\": 300,\n      \"height\": 253,\n      \"selected\": false,\n      \"positionAbsolute\": {\n        \"x\": 121.69949453914967,\n        \"y\": 742.2950675794249\n      },\n      \"dragging\": false\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"chatOpenAI_0\",\n      \"sourceHandle\": \"chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable\",\n      \"target\": \"conversationChain_0\",\n      \"targetHandle\": \"conversationChain_0-input-model-BaseChatModel\",\n      \"type\": \"buttonedge\",\n      \"id\": \"chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationChain_0-conversationChain_0-input-model-BaseChatModel\"\n    },\n    {\n      \"source\": \"bufferMemory_0\",\n      \"sourceHandle\": \"bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory\",\n      \"target\": \"conversationChain_0\",\n      \"targetHandle\": \"conversationChain_0-input-memory-BaseMemory\",\n      \"type\": \"buttonedge\",\n      \"id\": \"bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-conversationChain_0-conversationChain_0-input-memory-BaseMemory\"\n    }\n  ]\n}",
      "type": "CHATFLOW"
    }
  ],
  "AgentFlow": [],
  "Variable": [],
  "Assistant": []
}